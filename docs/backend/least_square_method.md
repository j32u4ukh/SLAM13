# 最小平方法(求最大似然估計)

假設最大似然服從高斯分佈，考慮**單次觀測**的最大似然估計，使用『最小化負對數(有較好的數學形式)』來求解。
由於對數函數是單調遞增的，所以『對原函數求最大化』相當於『對負對數求最小化』。

最小化上式右側的二次型項，則獲得對狀態的最大似然估計。這個二次型稱為『馬哈拉諾比斯距離(Mahalanobis)』，又叫『馬式距離』。
它可以看成由 Q^-1_k,j 加權之後的歐式距離(二範數)，這個 Q^-1_k,j 也叫做**資訊矩陣**，即高斯分佈共變異數矩陣之逆。

---

考慮**批次資料**，通常假設各個時刻的輸入和觀測是相互獨立的，各個輸入之間也是獨立的，各個觀測之間也是獨立的，於是可以對聯合分佈進行因式分解：

定義各次輸入和觀測資料與模型之間的誤差為：

最小化所有時刻估計值與真實讀數之間的馬式距離，相當於求最大似然估計，負對數允許我們把乘積變成求和：

將問題轉變成『最小平方問題(Least Square Problem)』。

## 非線性最小平方法

對複雜的函式求解最小平方問題，需要知道目標函式的**全域性質**，而這通常不太可能。這種情況可用**反覆運算**的方式，從一個初值出發，不斷更新目前的最佳化變數。

實際步驟如下：

1. 指定某個初值 X0。
2. 對於第 k 次反覆運算，尋找一個增量 ⊿Xk，使得增量後帶入目標函式達到極小值。
3. 若 ⊿Xk 足夠小，則停止。
4. 否則，令 X_k+1 = Xk + ⊿Xk，傳回第 2 步。

這讓『求解導函數為零』的問題，變成一個『不斷尋找下降增量 ⊿Xk』的問題。